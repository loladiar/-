#!/usr/bin/env jruby
require_relative 'p-topics'
%w{optparse open-uri csv json open3}.each { |e| require e }

$options = {}
OptionParser.new do |p|
  p.on('-s', '--skip-lines INTEGER', Integer, 'Skips processing as many lines as specified (default: 1).') { |v| $options[:skip_count] = v }
  p.on('-n', '--max-lines INTEGER',  Integer, 'Processes as many lines as specified.') { |v| $options[:max_lines] = v }
  p.on('-i', '--id-field INTEGER',   Integer, 'Specifies required comm. text id field.') { |v| $options[:id_field] = v }
  p.on('-q', '--q-field INTEGER',    Integer, 'Specifies required FAQ field.') { |v| $options[:q_field] = v }
  p.on('-f', '--fields i,j,k',       Array,   'Specifies required field indices to put into computation.') { |v| $options[:fields] = v }
  p.on('-m', '--model_id STRING',    String,  'Specifies optional model id.') { |v| $options[:model_id] = v }
end.parse!

max_lines = $options[:max_lines]
q_fields = ($options[:q_fields] || ['8']).map { |e| e.to_i }
fields = ($options[:fields] || ['1', '3']).map { |e| e.to_i }
model_id = $options[:model_id] || 'l-lda-0.75'
docs = ARGV
if docs.empty?
  docs = ["#{ENV['MAHOUT_WORK']}/test-set-2285-labeled_0.75.csv"]
  system "s3cmd get 's3://#{ENV['S3_BUCKET']}-private/resources/rrc_pro_2285_labeled_0.75.csv' '#{docs[0]}'" unless File.exists?(docs[0]) # rrc_pro_2285_labeled_typos
  # s3cmd get "s3://#{ENV['S3_BUCKET']}-private/resources/rrc_pro_1241_labeled.csv" "#{docs[0]}" unless File.exists?(docs[0]) # rrc_pro_2285_labeled_typos
end

q2cc = docs.reduce({}) do |h, e| # comm. texts keyed by FAQ.
  skip_count = $options[:skip_count] || 1
  CSV.open(e, 'r:windows-1250').each do |line|
    next if (skip_count -= 1) >= 0
    break unless max_lines.nil? || (max_lines -= 1) >= 0
    q = q_fields.map { |f| line[f] }.compact.map { |e| e.gsub(/\A\s+|\s+\Z/, '') }.join('; ')
    (h[q] ||= []) << c = fields.map { |f| line[f] }.join('; ') unless q.empty?
  end
  h
end

modeling = TopicModeling.new(model_id, true)
z2qf = q2cc.reduce({}) do |h, (q, cc)| # topic frequencies keyed by FAQ.
  cc.map { |c| putc '.'; modeling.p_topics(c) }.
    map { |p| p[0].nan?? -1 : p.each_with_index.max[1] }.
    reduce({}) { |zf, z| zf[z] = (zf[z] || 0) + 1; zf }.
    reduce(h) { |h, (z, f)| (h[z] ||= {})[q] = f; h }
end
puts

z2qf_max = z2qf.reduce({}) { |h, (z, qf)| h[z] = qf.values.max; h }
z2qf_sum = z2qf.reduce({}) { |h, (z, qf)| h[z] = qf.values.reduce(:+); h }

puts '### Frequences keyed by topic & FAQ: '
jj z2qf

puts '### Frequency max keyed by topic: '
jj z2qf_max

puts '### Frequency sum keyed by topic: '
jj z2qf_sum

puts "### Frequency sum keyed by FAQ: (#{q2cc.values.map { |cc| cc.size }.reduce(:+)} communications/#{q2cc.keys.size} questions)"
jj q2cc.reduce({}) { |h, (l, cc)| h[l] = cc.size; h }

puts '### Overall topic modeling accuracy: '
a, b = z2qf_max.values.reduce(:+), z2qf_sum.values.reduce(:+)
puts '%s / %s = %s%' % [a, b, (100.0 * a / b).round(1)]

exit 0
