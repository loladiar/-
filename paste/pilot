#!/usr/bin/env jruby
%W(optparse fileutils csv json #{ENV['HADOOP_BASE']}/libexec/lib/text-1.0-SNAPSHOT.jar).each { |e| require e }

class Analyzer
  def self.require_jars
    %w(
      com.google.guava:guava:14.0.1
      commons-logging:commons-logging:1.1.1
      log4j:log4j:1.2.17
      org.apache.avro:avro:1.5.3
      org.apache.commons:commons-math3:3.2
      org.apache.hadoop:hadoop-common:2.0.5-alpha
      org.apache.lucene:lucene-analyzers-common:4.3.0
      org.apache.lucene:lucene-core:4.3.0
      org.apache.mahout:mahout-core:0.8
      org.apache.mahout:mahout-math:0.8
      org.slf4j:slf4j-api:1.6.1
      org.slf4j:slf4j-log4j12:1.6.1
    ).map do |e|
      g, a, v = e.split(':')
      jar = "#{ENV['HOME']}/.m2/repository/#{g.gsub(/\./, '/')}/#{a}/#{v}/#{a}-#{v}.jar"
      system "mvn dependency:get -DremoteRepositories=http://download.java.net/maven2 -Dartifact=#{e}" unless File.exist?(jar)
      require jar
    end
  end

  def initialize(analyzer)
    @@jars ||= Analyzer.require_jars
    @analyzer = org.apache.mahout.common.lucene.AnalyzerUtils.createAnalyzer(analyzer)
  end

  def tokenize(text)
    stream = @analyzer.tokenStream("{field-name}", java.io.StringReader.new(text)).tap { |e| e.reset }
    term_attr = stream.add_attribute(org.apache.lucene.analysis.tokenattributes.CharTermAttribute.java_class)
    tokens = []
    begin
      tokens << java.lang.String.new(term_attr.buffer, 0, term_attr.length).to_s if term_attr.length > 0 while stream.increment_token
      tokens
    ensure
      stream.close
    end
  end
end

def parse_options
  options = {}
  OptionParser.new do |p|
    p.on('-s', '--skip-entries INTEGER', Integer, 'Skips processing as many entries as specified (default: 1).') { |v| $options[:skip_count] = v }
    p.on('-n', '--max-entries INTEGER', Integer, 'Processes as many entries as specified.') { |v| $options[:max_entries] = v }
    p.on('-i', '--id-field INTEGER', Integer, 'Specifies required field index for document id.') { |v| $options[:id_field] = v }
    p.on('-l', '--l-field INTEGER', Integer, 'Specifies required field index for label(s).') { |v| $options[:l_field] = v }
    p.on('-f', '--fields i,j,k', Array, 'Specifies required field indices for feature(s).') { |v| $options[:fields] = v }
    p.on('-r', '--stop-phrases PATH', String, 'Specifies optional file paths for stop-phrases.') { |v| $options[:stop_phrases] = v }
    p.on('-o', '--overwrite', 'Specifies whether to overwrite existing output.') { |v| $options[:overwrite] = v }
    p.on('-x', '--excludes x,y,z', Array, 'Specifies labels to exclude.') { |v| $options[:excludes] = v }
  end.parse!
  options
end

def run!
  analyzer = Analyzer.new('com.henry4j.text.CommTextAnalyzer')
  options = parse_options
  overwrite = options[:overwrite]
  skip_count = options[:skip_count] || 1
  max_entries = options[:max_entries]
  out_dir = options[:out_dir] || '/tmp'
  id_field = options[:id_field] || 0
  l_field = options[:l_field] || 8
  fields = (options[:fields] || ['4', '5']).map { |e| e.to_i }
  stop_phrases = options[:stop_phrases] || File.expand_path('../stop-comm-text', File.realpath(__FILE__))
  excludes = options[:excludes] || []

  corpus = File.join(ENV['MAHOUT_WORK'], 'corpus-3492-876.csv')

  stop_phrases = File.exists?(stop_phrases) ? open(stop_phrases).readlines.reduce([]) { |a, l| l.start_with?('#') ? a : a << l.chomp } : nil
  stop_phrases = /#{stop_phrases.join('|')}/ if stop_phrases

  lines_by_id = {}
  open(corpus, 'r:windows-1250') do |io|
    CSV.new(io).each do |l|
      next if (skip_count -= 1) >= 0
      next if l_field && l[l_field].nil?
      next if excludes.any? { |e| l[l_field].include?(e) }
      break if max_entries && (max_entries -= 1) < 0
      lines_by_id[l[id_field].strip] = l
    end
  end

  w = File.join(out_dir, 'corpus-engineered.csv')
  w = CSV.open(w, 'w:windows-1250')
  lines_by_id.sort.each do |id, l|
    begin
      s = fields.map { |f| l[f] }.compact.each { |f| stop_phrases ? f.gsub(stop_phrases, '.') : f }.join(' ')
      s = analyzer.tokenize(s).join(' ')
      w.puts [l[l_field], id, s]
    rescue
      raise 'Failed to process a line: %s.' % [l]
    end
    print id, ' '
  end
  exit 0
end

run! if __FILE__==$0
