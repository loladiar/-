#!/usr/bin/env jruby
%W(optparse open-uri fileutils csv json #{ENV['HADOOP_BASE']}/libexec/lib/text-1.0-SNAPSHOT.jar).each { |e| require e }

class Analyzer
  def self.require_jars
    %w(
      org.apache.lucene:lucene-analyzers-common:4.3.0
      org.apache.lucene:lucene-core:4.3.0
      org.apache.mahout:mahout-core:0.8
    ).map do |e|
      g, a, v = e.split(':')
      jar = "#{ENV['HOME']}/.m2/repository/#{g.gsub(/\./, '/')}/#{a}/#{v}/#{a}-#{v}.jar"
      system "mvn dependency:get -DremoteRepositories=http://download.java.net/maven2 -Dartifact=#{e}" unless File.exist?(jar)
      require jar
    end
  end

  def initialize(analyzer)
    @@jars ||= Analyzer.require_jars
    @analyzer = org.apache.mahout.common.lucene.AnalyzerUtils.createAnalyzer(analyzer)
  end

  def tokenize(text)
    stream = @analyzer.tokenStream('{field-name}', java.io.StringReader.new(text)).tap { |e| e.reset }
    term_attr = stream.add_attribute(org.apache.lucene.analysis.tokenattributes.CharTermAttribute.java_class)
    tokens = []
    begin
      tokens << java.lang.String.new(term_attr.buffer, 0, term_attr.length).to_s if term_attr.length > 0 while stream.increment_token
      tokens
    ensure
      stream.close
    end
  end
end

def parse_options
  options = {}
  OptionParser.new do |p|
    p.on('-r', '--stop-phrases PATH', String, 'Specifies optional file paths for stop-phrases.') { |v| options[:stop_phrases] = v }
  end.parse!
  options
end

def run!
  analyzer = Analyzer.new('com.henry4j.text.CommTextAnalyzer')
  options = parse_options
  stop_phrases = options[:stop_phrases] || File.expand_path('../stop-comm-text', File.realpath(__FILE__))

  stop_phrases = File.exists?(stop_phrases) ? open(stop_phrases).readlines.reduce([]) { |a, l| l.start_with?('#') ? a : a << l.chomp } : nil
  stop_phrases = /#{stop_phrases.join('|')}/ if stop_phrases

  lines_by_id = {}
  argf = ARGV.empty? ? [$stdin] : ARGV.map { |e| open(e, 'r:windows-1250') }
  begin
    argf.each do |io|
      io.each do |l|
        l.gsub!(stop_phrases, '.') if stop_phrases
        puts analyzer.tokenize(l).join(' ')
      end
    end
  ensure
    argf.each { |io| io.close } 
  end
  exit 0
end

run! if __FILE__==$0
