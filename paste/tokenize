#!/usr/bin/env jruby -E windows-1250
%W(open-uri #{ENV['HADOOP_BASE']}/libexec/lib/text-1.0-SNAPSHOT.jar).each { |e| require e }

class Analyzer
  def self.require_jars
    %w(
      org.apache.lucene:lucene-analyzers-common:4.3.0
      org.apache.lucene:lucene-core:4.3.0
      org.apache.mahout:mahout-core:0.8
    ).map do |e|
      g, a, v = e.split(':')
      jar = "#{ENV['HOME']}/.m2/repository/#{g.gsub(/\./, '/')}/#{a}/#{v}/#{a}-#{v}.jar"
      system "mvn dependency:get -DremoteRepositories=http://download.java.net/maven2 -Dartifact=#{e}" unless File.exist?(jar)
      require jar
    end
  end

  def initialize(analyzer)
    @@jars ||= Analyzer.require_jars
    @analyzer = org.apache.mahout.common.lucene.AnalyzerUtils.createAnalyzer(analyzer)
  end

  def tokenize(text)
    stream = @analyzer.tokenStream('{field-name}', java.io.StringReader.new(text)).tap { |e| e.reset }
    term_attr = stream.add_attribute(org.apache.lucene.analysis.tokenattributes.CharTermAttribute.java_class)
    tokens = []
    begin
      tokens << java.lang.String.new(term_attr.buffer, 0, term_attr.length).to_s if term_attr.length > 0 while stream.increment_token
      tokens
    ensure
      stream.close
    end
  end
end

analyzer = Analyzer.new('com.henry4j.text.CommTextAnalyzer')
stop_phrases = %r(#{open('https://goo.gl/oLljZW').readlines.reduce([]) { |a, e| e[0] == '#' ? a : a << e.chomp }.join('|')})

ARGF.each { |e| $stdout.puts analyzer.tokenize(e.gsub(stop_phrases, '.')).join(' ') }
