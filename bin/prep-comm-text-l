#!/usr/bin/env jruby
%w{optparse fileutils open-uri csv json}.each { |e| require e }
%w(
  com.google.guava:guava:14.0.1
  commons-configuration:commons-configuration:1.6
  commons-logging:commons-logging:1.1.1
  commons-lang:commons-lang:2.5
  log4j:log4j:1.2.17
  org.apache.avro:avro:1.5.3
  org.apache.commons:commons-math3:3.2
  org.apache.hadoop:hadoop-common:2.0.5-alpha
  org.apache.hadoop:hadoop-annotations:2.0.5-alpha
  org.apache.hadoop:hadoop-auth:2.0.5-alpha
  org.apache.lucene:lucene-analyzers-common:4.3.0
  org.apache.lucene:lucene-core:4.3.0
  org.apache.mahout:mahout-core:0.8
  org.apache.mahout:mahout-math:0.8
  org.slf4j:slf4j-api:1.6.1
  org.slf4j:slf4j-log4j12:1.6.1
).map do |e|
  g, a, v = e.split(':')
  jar = "#{ENV['HOME']}/.m2/repository/#{g.gsub(/\./, '/')}/#{a}/#{v}/#{a}-#{v}.jar"
  system "mvn dependency:get -DremoteRepositories=http://download.java.net/maven2 -Dartifact=#{e}" unless File.exist?(jar)
  require jar
end

$options = {}
OptionParser.new do |p|
  p.on('-s', '--skip-entries INTEGER', Integer, 'Skips processing as many entries as specified (default: 1).') { |v| $options[:skip_count] = v }
  p.on('-n', '--max-entries INTEGER', Integer, 'Processes as many entries as specified.') { |v| $options[:max_entries] = v }
  p.on('-d', '--out-dir PATH', String, 'Specifies an optional output directory path (default: /tmp/).') { |v| $options[:out_dir] = v }
  p.on('-i', '--id-field INTEGER', Integer, 'Specifies required field index for document id.') { |v| $options[:id_field] = v }
  p.on('-l', '--l-field INTEGER', Integer, 'Specifies required field index for label(s).') { |v| $options[:l_field] = v }
  p.on('-f', '--fields i,j,k', Array, 'Specifies required field indices for feature(s).') { |v| $options[:fields] = v }
  p.on('-x', '--stop-phrases PATH', String, 'Specifies optional file paths for stop-phrases.') { |v| $options[:stop_phrases] = v }
end.parse!

max_entries = $options[:max_entries]
out_dir = $options[:out_dir] || '/tmp/'
id_field = $options[:id_field] || 4
l_field = $options[:l_field] # || 8
fields = ($options[:fields] || ['1', '3']).map { |e| e.to_i }
stop_phrases = $options[:stop_phrases] || File.expand_path('../stop-comm-text', File.realpath(__FILE__))
stop_phrases = File.exists?(stop_phrases) ? open(stop_phrases).readlines.reduce([]) { |a, l| l.start_with?('#') ? a : a << l.chomp } : nil
stop_phrases = /#{stop_phrases.join('|')}/ if stop_phrases
label_ids = {}
labels_by_doc_id = {}

fail "'corpus' must be specified." unless (corpus = ARGV[0])
open(corpus, 'r:windows-1250') do |f|
  skip_count = $options[:skip_count] || 1
  FileUtils.rm_rf out_dir
  FileUtils.mkdir_p out_dir
  CSV.new(f).each do |l|
    next if (skip_count -= 1) >= 0
    next if l_field && (labels = l[l_field]).nil?
    break if max_entries && (max_entries -= 1) < 0
    path = File.join(out_dir, (id = l[id_field].strip) + ".txt")
    open(path, 'w:UTF-8') do |w| 
      fields.each do |f| 
        begin
          w.puts stop_phrases ? l[f].gsub(stop_phrases, '.') : l[f] if l[f]
          labels_by_doc_id[id] = labels.split('|').map { |e| e.strip }.map { |e| label_ids[e] ||= label_ids.size } if l_field
          puts "INFO: done writing to '#{path}'."
        rescue
          raise 'Failed to process a line: %s.' % [l]
        end
      end
    end
  end
end
if l_field
  corpus_priors = org.apache.mahout.math.SparseRowMatrix.new(labels_by_doc_id.size, label_ids.size, true) # true for random access
  labels_by_doc_id.sort.each_with_index { |(k, v), i| v.each { |l| corpus_priors.view_row(i).set_quick(l, 1.0/v.size) } }
  path = org.apache.hadoop.fs.Path.new("file:///#{File.join(File.dirname(corpus), File.basename(corpus, '.*') + '-priors')}")
  conf = org.apache.hadoop.conf.Configuration.new
  org.apache.mahout.math.MatrixUtils.write(path, conf, corpus_priors)
end
exit 0
